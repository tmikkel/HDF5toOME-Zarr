{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad728f07-faff-4b0b-afe1-9a58e5d16474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported succesfully!\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import zarr\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import dask\n",
    "from dask import delayed\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "from numcodecs import Blosc\n",
    "from pathlib import Path\n",
    "import dask_memusage\n",
    "import gc\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "from dask.distributed import Client, LocalCluster, as_completed, get_worker\n",
    "\n",
    "print(\"All libraries imported succesfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63d281e5-479f-4b78-aac1-138d7cf7282e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem per worker (bytes): 1500000000.0\n",
      "Mem per worker (GB): 1.5\n"
     ]
    }
   ],
   "source": [
    "# Conversion arguments\n",
    "\n",
    "input_path = \"/Users/tobiasschleiss/documents/dtu/thesis/input/small_wMB_4bin.h5\"\n",
    "output_path = \"/Users/tobiasschleiss/Documents/DTU/Thesis/output/output2.ome.zarr\"\n",
    "target_chunks = (64, 64, 64)\n",
    "dataset_path = 'exchange/data'\n",
    "temp_chunk_size=(64, 512, 512)\n",
    "max_mem_gb=15\n",
    "pyramid_levels = 5\n",
    "downsample_factor=2\n",
    "compression_level=3\n",
    "target_top_level_mb=100\n",
    "safety_factor = 0.80\n",
    "\n",
    "available_bytes = max_mem_gb * 1e9 * safety_factor\n",
    "\n",
    "n_workers = 8\n",
    "mem_divider = 24\n",
    "threads_per_worker=1\n",
    "memory_limit = available_bytes/n_workers\n",
    "print(f\"Mem per worker (bytes): {memory_limit}\")\n",
    "print(f\"Mem per worker (GB): {(memory_limit/1e9)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b98cbfd-5a4c-4672-96cc-fccedeb66b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Shape: (1651, 2200, 2200)\n",
      "  Dtype: float32\n",
      "  Size: 29.77 GB\n",
      "  HDF5 chunks: Contiguous\n"
     ]
    }
   ],
   "source": [
    "# Inspect HDF5 file\n",
    "with h5py.File(input_path, 'r') as f:\n",
    "    if dataset_path not in f:\n",
    "        print(f\"  ERROR: Dataset '{dataset_path}' not found\")\n",
    "        print(f\"  Available paths: {list(f.keys())}\")\n",
    "        \n",
    "    dataset = f[dataset_path]\n",
    "    shape = dataset.shape\n",
    "    dtype = dataset.dtype\n",
    "    h5_chunks = dataset.chunks\n",
    "    data_size_gb = dataset.nbytes / (1024**3)\n",
    "    data_size_mb = dataset.nbytes / (1024**2)\n",
    "    dtype_size = dtype.itemsize\n",
    "        \n",
    "    print(f\"  Shape: {shape}\")\n",
    "    print(f\"  Dtype: {dtype}\")\n",
    "    print(f\"  Size: {data_size_gb:.2f} GB\")\n",
    "    print(f\"  HDF5 chunks: {h5_chunks if h5_chunks else 'Contiguous'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2159d96-80bc-499d-a43d-6579bdfe48a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target top level: 100 MB\n",
      "Recommended levels: 4\n",
      "Actual top level: 59.5 MB\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Calculate pyramid levels based on target top-level size\"\"\"\n",
    "    \n",
    "# Calculate levels needed\n",
    "levels = 1\n",
    "current_size_mb = data_size_mb\n",
    "    \n",
    "while current_size_mb > target_top_level_mb:\n",
    "    current_size_mb = current_size_mb / (downsample_factor ** 3)\n",
    "    levels += 1\n",
    "\n",
    "print(f\"Target top level: {target_top_level_mb} MB\")\n",
    "print(f\"Recommended levels: {levels}\")\n",
    "print(f\"Actual top level: {current_size_mb:.1f} MB\")\n",
    "\n",
    "pyramid_levels = levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c802aa04-dbad-4d1e-b12e-9272fe34b0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "\n",
      "Full Target Z plane (64) too large for memory\n",
      "Reducing Y axis to fit block in memory\n",
      "\n",
      "============================================================\n",
      "Optimal Block Size Calculation\n",
      "============================================================\n",
      "Memory budget: 15.00 GB (using 80%)\n",
      "Available for block: 0.50 GB\n",
      "Actual block size: 0.47 GB\n",
      "============================================================\n",
      "Read chunks: (64, 832, 2200)\n"
     ]
    }
   ],
   "source": [
    "z, y, x = shape\n",
    "block_z, block_y, block_x = target_chunks\n",
    "    \n",
    "# Available memory given safety factor\n",
    "available_bytes = (max_mem_gb * safety_factor / mem_divider) * 1e9\n",
    "\n",
    "print(mem_divider)\n",
    "    \n",
    "# Calculate maximum amount of Z-planes that fit in memory\n",
    "bytes_per_z_plane = y * x * dtype_size\n",
    "max_z_planes = int(available_bytes / bytes_per_z_plane)\n",
    "\n",
    "if max_z_planes >= block_z:\n",
    "    # Align to target_z for efficient zarr chunking\n",
    "    # Use largest multiple of target_z that fits\n",
    "    optimal_z = (max_z_planes // block_z) * block_z\n",
    "    optimal_z = max(block_z, optimal_z)  # At least one chunk depth\n",
    "    optimal_z = min(optimal_z, z)   # Don't exceed dataset\n",
    "    block_z = optimal_z\n",
    "else:\n",
    "    print(f\"\\nFull Target Z plane ({target_chunks[0]}) too large for memory\")\n",
    "    print(\"Reducing Y axis to fit block in memory\")\n",
    "    \n",
    "    # Calculate max Y that fits with target Z and full X\n",
    "    bytes_per_y_row = block_z * x * dtype_size\n",
    "    max_y_rows = int(available_bytes / bytes_per_y_row)\n",
    "    optimal_y = (max_y_rows // block_y) * block_y \n",
    "    optimal_y = max(block_y, optimal_y)  # At least one chunk depth\n",
    "    if max_y_rows >= y/2+block_y:\n",
    "        optimal_y = int(min(optimal_y, ((y/2)//block_y)*block_y+block_y))   # Don't exceed half of y + target_y\n",
    "    y = optimal_y\n",
    "\n",
    "block_shape = block_z, y, x\n",
    "    \n",
    "# Calculate actual memory usage\n",
    "actual_gb = block_z * y * x * dtype_size / 1e9\n",
    "    \n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Optimal Block Size Calculation\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Memory budget: {max_mem_gb:.2f} GB (using {int(safety_factor*100)}%)\")\n",
    "print(f\"Available for block: {available_bytes/1e9:.2f} GB\")\n",
    "print(f\"Actual block size: {actual_gb:.2f} GB\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Read chunks: {block_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dbec400-841b-42b4-ba0e-74c6550158ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: entering hybrid_conversion\n",
      "block shape: (64, 832, 2200)\n",
      "Number of Workers: 8 memory per worker 1500000000.0\n",
      "Dask dashboard: http://127.0.0.1:8787/status\n",
      "Memory logging to: /Users/tobiasschleiss/Documents/DTU/Thesis/output/memusage.csv\n",
      "\n",
      "✓ Submitting 78 tasks for parallel execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:36: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "  store = zarr.NestedDirectoryStore(output_path)\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 1\n",
      "completed blocks: 2\n",
      "completed blocks: 3\n",
      "completed blocks: 4\n",
      "completed blocks: 5\n",
      "completed blocks: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 9\n",
      "completed blocks: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 12\n",
      "completed blocks: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 17\n",
      "completed blocks: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 19\n",
      "completed blocks: 20\n",
      "completed blocks: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 22\n",
      "completed blocks: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 26\n",
      "completed blocks: 27\n",
      "completed blocks: 28\n",
      "completed blocks: 29\n",
      "completed blocks: 30\n",
      "completed blocks: 31\n",
      "completed blocks: 32\n",
      "completed blocks: 33\n",
      "completed blocks: 34\n",
      "completed blocks: 35\n",
      "completed blocks: 36\n",
      "completed blocks: 37\n",
      "completed blocks: 38\n",
      "completed blocks: 39\n",
      "completed blocks: 40\n",
      "completed blocks: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 45\n",
      "completed blocks: 46\n",
      "completed blocks: 47\n",
      "completed blocks: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 52\n",
      "completed blocks: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 54\n",
      "completed blocks: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 56\n",
      "completed blocks: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 59\n",
      "completed blocks: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 62\n",
      "completed blocks: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 67\n",
      "completed blocks: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 69\n",
      "completed blocks: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_7990/4193733033.py:55: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed blocks: 71\n",
      "completed blocks: 72\n",
      "completed blocks: 73\n",
      "completed blocks: 74\n",
      "completed blocks: 75\n",
      "completed blocks: 76\n",
      "completed blocks: 77\n",
      "completed blocks: 78\n",
      "\n",
      "✓ Complete: 39.0s | 0.82 GB/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread WorkerMemory:\n",
      "ConnectionRefusedError: [Errno 61] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/comm/core.py\", line 342, in connect\n",
      "    comm = await wait_for(\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/utils.py\", line 1930, in wait_for\n",
      "    return await fut\n",
      "           ^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 560, in connect\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 143, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x16b418230>: ConnectionRefusedError: [Errno 61] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/dask_memusage.py\", line 66, in _fetch_memory\n",
      "    worker_to_mem = client.run(_process_memory)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/client.py\", line 3199, in run\n",
      "    return self.sync(\n",
      "           ^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/utils.py\", line 383, in sync\n",
      "    return sync(\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/utils.py\", line 459, in sync\n",
      "    raise error\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/utils.py\", line 433, in f\n",
      "    result = yield future\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/tornado/gen.py\", line 783, in run\n",
      "    value = future.result()\n",
      "            ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/client.py\", line 3076, in _run\n",
      "    responses = await self.scheduler.broadcast(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/core.py\", line 1256, in send_recv_from_rpc\n",
      "    comm = await self.pool.connect(self.addr)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/core.py\", line 1485, in connect\n",
      "    return await self._connect(addr=addr, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/core.py\", line 1429, in _connect\n",
      "    comm = await connect(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/comm/core.py\", line 368, in connect\n",
      "    raise OSError(\n",
      "OSError: Timed out trying to connect to tcp://127.0.0.1:62226 after 30 s\n",
      "2026-02-12 17:42:45,529 - distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n"
     ]
    }
   ],
   "source": [
    "print(\"DEBUG: entering hybrid_conversion\")\n",
    "\n",
    "with h5py.File(input_path, \"r\") as f:\n",
    "        dataset = f[dataset_path]\n",
    "        shape = dataset.shape\n",
    "        dtype = dataset.dtype\n",
    "        dtype_size = dtype.itemsize\n",
    "        data_size_mb = dataset.nbytes / (1024**2)\n",
    "    \n",
    "        print(f\"block shape: {block_shape}\")\n",
    "\n",
    "        block_z, block_y, block_x = block_shape\n",
    "        z_total, y_total, x_total = shape\n",
    "\n",
    "        # For hybrid conversion block_z shouldn't be greater than target_z\n",
    "        block_z = target_chunks[0]\n",
    "        \n",
    "\n",
    "read_chunks_bytes = np.prod(block_shape) * dtype_size\n",
    "\n",
    "print(f\"Number of Workers: {n_workers} memory per worker {memory_limit}\")\n",
    "\n",
    "cluster = LocalCluster(\n",
    "    n_workers=n_workers,\n",
    "    threads_per_worker=1,\n",
    "    processes=True,\n",
    "    memory_limit=memory_limit\n",
    ")\n",
    "client = Client(cluster)\n",
    "print(f\"Dask dashboard: {client.dashboard_link}\")\n",
    "\n",
    "log_path = Path(\"/Users/tobiasschleiss/Documents/DTU/Thesis/output/\") / \"memusage.csv\"  # Save in output folder\n",
    "dask_memusage.install(cluster.scheduler, str(log_path))\n",
    "print(f\"Memory logging to: {log_path}\")\n",
    "\n",
    "store = zarr.NestedDirectoryStore(output_path)\n",
    "root = zarr.open_group(store, mode=\"w\")\n",
    "compressor = Blosc(cname=\"zstd\", clevel=compression_level, shuffle=Blosc.BITSHUFFLE)\n",
    "\n",
    "root.create_dataset(\n",
    "    \"0\",\n",
    "    shape=shape,\n",
    "    chunks=target_chunks,\n",
    "    dtype=dtype,\n",
    "    compressor=compressor\n",
    ")\n",
    "\n",
    "del root, store\n",
    "\n",
    "@dask.delayed\n",
    "def copy_block(z_start, z_end, y_start, y_end, x_start, x_end):\n",
    "    with h5py.File(input_path, \"r\") as f:\n",
    "        block = f[dataset_path][z_start:z_end, y_start:y_end, x_start:x_end]\n",
    "    \n",
    "    store = zarr.NestedDirectoryStore(output_path)\n",
    "    root = zarr.open_group(store, mode=\"a\")\n",
    "    root[\"0\"][z_start:z_end, y_start:y_end, x_start:x_end] = block\n",
    "\n",
    "    return (z_end - z_start, y_end - y_start, x_end - x_start)\n",
    "\n",
    "tasks = []\n",
    "for z_start in range(0, z_total, block_z):\n",
    "    z_end = min(z_start + block_z, shape[0])\n",
    "\n",
    "    for y_start in range(0, y_total, block_y):\n",
    "        y_end = min(y_start + block_y, y_total)\n",
    "\n",
    "        for x_start in range(0, x_total, block_x):\n",
    "            x_end = min(x_start + block_x, x_total)\n",
    "\n",
    "            tasks.append(copy_block(z_start, z_end, y_start, y_end, x_start, x_end))\n",
    "\n",
    "total_tasks = len(tasks)\n",
    "print(f\"\\n✓ Submitting {total_tasks} tasks for parallel execution...\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Submit all tasks and get futures\n",
    "futures = client.compute(tasks)\n",
    "\n",
    "# Track progress\n",
    "completed = 0\n",
    "\n",
    "for future in as_completed(futures):\n",
    "    completed += 1\n",
    "    elapsed = time.time() - start\n",
    "    rate = completed / elapsed if elapsed > 0 else 0\n",
    "    eta = (total_tasks - completed) / rate if rate > 0 else 0\n",
    "    \n",
    "    print(f\"completed blocks: {completed}\")\n",
    "\n",
    "elapsed = time.time() - start\n",
    "\n",
    "total_gb = np.prod(shape) * dtype_size / 1e9\n",
    "\n",
    "print(f\"\\n✓ Complete: {elapsed:.1f}s | {total_gb/elapsed:.2f} GB/s\")\n",
    "\n",
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "362efef0-612b-4b8a-a905-209916dd4962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Source chunks: (64, 64, 64)\n",
      "  Source shape: (1651, 2200, 2200)\n",
      "  Source dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# Inspection level_0\n",
    "source = da.from_zarr(output_path, component='0')\n",
    "    \n",
    "print(f\"  Source chunks: {source.chunksize}\")\n",
    "print(f\"  Source shape: {source.shape}\")\n",
    "print(f\"  Source dtype: {source.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed671f6a-24b9-4601-a524-669042ad27b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3c05f4a-b6e9-4e40-ab96-cf26da8cd9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/node.py:188: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 62417 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask dashboard: http://127.0.0.1:62417/status\n",
      "============================================================\n",
      "Building OME-Zarr Multi-Resolution Pyramid (Block-Mean)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "LEVEL 1: Block-Mean Downsampling\n",
      "============================================================\n",
      "Previous shape: (1651, 2200, 2200)\n",
      "New shape: (825, 1100, 1100)\n",
      "Total tasks for current level: 4212\n",
      "Total recurring in flights: 32\n",
      "completed: 1\n",
      "completed: 2\n",
      "completed: 3\n",
      "completed: 4\n",
      "completed: 5\n",
      "completed: 6\n",
      "completed: 7\n",
      "completed: 8\n",
      "completed: 9\n",
      "completed: 10\n",
      "completed: 11\n",
      "completed: 12\n",
      "completed: 13\n",
      "completed: 14\n",
      "completed: 15\n",
      "completed: 16\n",
      "completed: 17\n",
      "completed: 18\n",
      "completed: 19\n",
      "completed: 20\n",
      "completed: 21\n",
      "completed: 22\n",
      "completed: 23\n",
      "completed: 24\n",
      "completed: 25\n",
      "completed: 26\n",
      "completed: 27\n",
      "completed: 28\n",
      "completed: 29\n",
      "completed: 30\n",
      "completed: 31\n",
      "completed: 32\n",
      "Finished level 1 in 19.2s\n",
      "\n",
      "============================================================\n",
      "LEVEL 2: Block-Mean Downsampling\n",
      "============================================================\n",
      "Previous shape: (825, 1100, 1100)\n",
      "New shape: (412, 550, 550)\n",
      "Total tasks for current level: 567\n",
      "Total recurring in flights: 4\n",
      "completed: 1\n",
      "completed: 2\n",
      "completed: 3\n",
      "completed: 4\n",
      "Finished level 2 in 2.5s\n",
      "\n",
      "============================================================\n",
      "LEVEL 3: Block-Mean Downsampling\n",
      "============================================================\n",
      "Previous shape: (412, 550, 550)\n",
      "New shape: (206, 275, 275)\n",
      "Total tasks for current level: 100\n",
      "Total recurring in flights: 0\n",
      "Finished level 3 in 0.3s\n",
      "\n",
      "Total pyramid time: 0.37 minutes\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import zarr\n",
    "\n",
    "from dask.distributed import Client, LocalCluster, wait\n",
    "from numcodecs import Blosc\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Worker Task: Block Mean Downsampling\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def mean_downsample_block(\n",
    "    source_path,\n",
    "    destination_path,\n",
    "    block_region,\n",
    "    destination_coords,\n",
    "    downsample_factor\n",
    "):\n",
    "    \"\"\"\n",
    "    Each worker task:\n",
    "    1. Opens source and destination Zarr arrays.\n",
    "    2. Reads source block.\n",
    "    3. Trims it to dimensions divisible by downsample_factor.\n",
    "    4. Computes block mean over each non-overlapping cube of size downsample_factor.\n",
    "    5. Writes the downsampled block to the destination array.\n",
    "    \"\"\"\n",
    "    src = zarr.open(source_path, mode=\"r\")\n",
    "    store = zarr.open(destination_path, mode=\"r+\")\n",
    "\n",
    "    block = src[block_region]\n",
    "\n",
    "    d = downsample_factor\n",
    "\n",
    "    # Trim dimensions to be divisible by downsample factor\n",
    "    block_z = (block.shape[0] // d) * d\n",
    "    block_y = (block.shape[1] // d) * d\n",
    "    block_x = (block.shape[2] // d) * d\n",
    "    block = block[:block_z, :block_y, :block_x]\n",
    "\n",
    "    # Reshape to compute block mean\n",
    "    # Each axis is split into (num_blocks, block_size)\n",
    "    reshaped = block.reshape(\n",
    "        block_z // d, d,\n",
    "        block_y // d, d,\n",
    "        block_x // d, d\n",
    "    )\n",
    "\n",
    "    # Compute mean over the block axes (1,3,5) (downsample the block)\n",
    "    downsampled = reshaped.mean(axis=(1, 3, 5)).astype(block.dtype)\n",
    "\n",
    "    # Write to pyramid array\n",
    "    store[destination_coords] = downsampled\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Build One Pyramid Level\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def build_level(\n",
    "    client,\n",
    "    output_path,\n",
    "    level,\n",
    "    downsample_factor,\n",
    "    target_chunks,\n",
    "    compressor,\n",
    "    max_in_flight=128\n",
    "):\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"LEVEL {level}: Block-Mean Downsampling\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    source_path = os.path.join(output_path, str(level - 1))\n",
    "    destination_path = os.path.join(output_path, str(level))\n",
    "\n",
    "    #load previous level as source\n",
    "    source = zarr.open(source_path, mode=\"r\")\n",
    "    current_shape = source.shape\n",
    "    new_shape = tuple(max(1, s // downsample_factor) for s in current_shape)\n",
    "\n",
    "    print(f\"Previous shape: {current_shape}\")\n",
    "    print(f\"New shape: {new_shape}\")\n",
    "\n",
    "    # Create destination array\n",
    "    zarr.open(\n",
    "        destination_path,\n",
    "        mode=\"w\",\n",
    "        shape=new_shape,\n",
    "        chunks=target_chunks,\n",
    "        dtype=source.dtype,\n",
    "        compressor=compressor,\n",
    "        dimension_separator=\"/\"\n",
    "    )\n",
    "\n",
    "    futures = []\n",
    "    \n",
    "    chunk_z, chunk_y, chunk_x = target_chunks\n",
    "\n",
    "    current_total_tasks = (\n",
    "        (int(np.ceil(new_shape[0] / chunk_z)))*\n",
    "        (int(np.ceil(new_shape[1] / chunk_y)))*\n",
    "        (int(np.ceil(new_shape[2] / chunk_x)))\n",
    "    )\n",
    "    print(f\"Total tasks for current level: {current_total_tasks}\")\n",
    "\n",
    "    print(f\"Total recurring in flights: {current_total_tasks // max_in_flight}\")\n",
    "\n",
    "    level_start = time.time()\n",
    "    \n",
    "    completed = 0\n",
    "\n",
    "    # Iterate over output blocks\n",
    "    for z_start in range(0, new_shape[0], chunk_z):\n",
    "        for y_start in range(0, new_shape[1], chunk_y):\n",
    "            for x_start in range(0, new_shape[2], chunk_x):\n",
    "\n",
    "                #Tuple holding python slice objects (block write coordinates)\n",
    "                destination_coords = (\n",
    "                    slice(z_start, min(z_start + chunk_z, new_shape[0])),\n",
    "                    slice(y_start, min(y_start + chunk_y, new_shape[1])),\n",
    "                    slice(x_start, min(x_start + chunk_x, new_shape[2])),\n",
    "                )\n",
    "\n",
    "                # Mapping block\n",
    "                source_start = (\n",
    "                    z_start * downsample_factor,\n",
    "                    y_start * downsample_factor,\n",
    "                    x_start * downsample_factor,\n",
    "                )\n",
    "                source_end = (\n",
    "                    min((z_start + chunk_z) * downsample_factor, current_shape[0]),\n",
    "                    min((y_start + chunk_y) * downsample_factor, current_shape[1]),\n",
    "                    min((x_start + chunk_x) * downsample_factor, current_shape[2]),\n",
    "                )\n",
    "\n",
    "                #Tuple holding python slice objects (Block to be read from current array)\n",
    "                block_region = (\n",
    "                    slice(source_start[0], source_end[0]),\n",
    "                    slice(source_start[1], source_end[1]),\n",
    "                    slice(source_start[2], source_end[2])\n",
    "                )\n",
    "\n",
    "                # Submit the block task\n",
    "                future = client.submit(\n",
    "                    mean_downsample_block,\n",
    "                    source_path,\n",
    "                    destination_path,\n",
    "                    block_region,\n",
    "                    destination_coords,\n",
    "                    downsample_factor\n",
    "                )\n",
    "\n",
    "                futures.append(future)\n",
    "\n",
    "                if len(futures) >= max_in_flight:\n",
    "                    completed += 1\n",
    "                    print(f\"completed: {completed}\")\n",
    "                    wait(futures)\n",
    "                    futures = []\n",
    "\n",
    "    if futures:\n",
    "        wait(futures)\n",
    "\n",
    "    print(f\"Finished level {level} in {(time.time() - level_start):.1f}s\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Main Pyramid Builder\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "cluster = LocalCluster(\n",
    "    n_workers=n_workers,\n",
    "    threads_per_worker=1,\n",
    "    processes=True,\n",
    "    memory_limit=memory_limit\n",
    ")\n",
    "client = Client(cluster)\n",
    "print(f\"Dask dashboard: {client.dashboard_link}\")\n",
    "print(\"=\"*60)\n",
    "print(\"Building OME-Zarr Multi-Resolution Pyramid (Block-Mean)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "compressor = Blosc(\n",
    "    cname=\"zstd\",\n",
    "    clevel=compression_level,\n",
    "    shuffle=Blosc.BITSHUFFLE\n",
    ")\n",
    "\n",
    "pyramid_start = time.time()\n",
    "for level in range(1, pyramid_levels):\n",
    "    build_level(\n",
    "        client,\n",
    "        output_path,\n",
    "        level,\n",
    "        downsample_factor,\n",
    "        target_chunks,\n",
    "        compressor\n",
    "    )\n",
    "\n",
    "print(\"\\nTotal pyramid time: \"\n",
    "      f\"{(time.time() - pyramid_start)/60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7567b3c-b231-4240-872c-4e88b6d66b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/node.py:188: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 62484 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask dashboard: http://127.0.0.1:62484/status\n",
      "\n",
      "============================================================\n",
      "Building OME-Zarr Multi-Resolution Pyramid (Gaussian)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "LEVEL 1: Gaussian Downsampling\n",
      "============================================================\n",
      "Previous shape: (1651, 2200, 2200)\n",
      "New shape: (825, 1100, 1100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-12 17:46:31,660 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute('gaussian_downsample_block-e39db916a27c9fc740e8e047ca02aaed')\" coro=<Worker.execute() done, defined at /opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError\n",
      "2026-02-12 17:46:31,661 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute('gaussian_downsample_block-552e7ecd052db5cbe8631813e349f468')\" coro=<Worker.execute() done, defined at /opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError\n",
      "2026-02-12 17:46:31,667 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute('gaussian_downsample_block-b2a3de540e13c3c094f2c0b5692e3406')\" coro=<Worker.execute() done, defined at /opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError\n",
      "2026-02-12 17:46:31,668 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute('gaussian_downsample_block-5a0621d0c65796361312b009d290fcfa')\" coro=<Worker.execute() done, defined at /opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError\n",
      "2026-02-12 17:46:31,668 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute('gaussian_downsample_block-79dc750d0bcd4181d0f4cb28497f4f04')\" coro=<Worker.execute() done, defined at /opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError\n",
      "2026-02-12 17:46:31,668 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute('gaussian_downsample_block-09d04fb066e84de132f722312adbf9b1')\" coro=<Worker.execute() done, defined at /opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError\n",
      "2026-02-12 17:46:31,669 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute('gaussian_downsample_block-b4ef0319f29ddb23531f1bd8a6487618')\" coro=<Worker.execute() done, defined at /opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError\n",
      "2026-02-12 17:46:31,669 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute('gaussian_downsam2026-02-12 17:46:31,723 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:62517' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'gaussian_downsample_block-d7aee502c7a57c11c27db78d842ba60c', 'gaussian_downsample_block-dbd71ac4c159d0ec3779c0431e29bd4c', 'gaussian_downsample_block-68f58938be2fb32becd153a95ecb701b'} (stimulus_id='handle-worker-cleanup-1770914791.723511')\n",
      "ple_block-4fc6354ce0e1b4840bbff92d42e960ef')\" coro=<Worker.execute() done, defined at /opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError\n",
      "2026-02-12 17:46:31,674 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 226, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/worker.py\", line 1273, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/utils_comm.py\", line 416, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/utils_comm.py\", line 395, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/core.py\", line 1259, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/core.py\", line 1018, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 137, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:62537 remote=tcp://127.0.0.1:62485>: Stream is closed\n",
      "2026-02-12 17:46:31,730 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:62518' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'gaussian_downsample_block-9bc2a6971da2488bf3b22eb0079d19ad', 'gaussian_downsample_block-6fbd5985ab23fb57a0ac688a55005ae6', 'gaussian_downsample_block-7aa9664db3355287f2ec814100b788b5'} (stimulus_id='handle-worker-cleanup-1770914791.7306619')\n",
      "2026-02-12 17:46:31,904 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:62506' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'gaussian_downsample_block-b19fe96330e18d064c87c96757d839e0', 'gaussian_downsample_block-14656eda3f3d2690321569c81c5090f9', 'gaussian_downsample_block-0d034e6be499459d7ca760f442d2f75d'} (stimulus_id='handle-worker-cleanup-1770914791.904377')\n",
      "2026-02-12 17:46:31,907 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:62504' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'gaussian_downsample_block-cd93c02561308f0241dcdbf80f81516b', 'gaussian_downsample_block-8f2eb3d65b9537421f26cf2d58a54b9a', 'gaussian_downsample_block-974e64a688d10967d6abc8641f7be9ca'} (stimulus_id='handle-worker-cleanup-1770914791.9079008')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 211\u001b[39m\n\u001b[32m    207\u001b[39m pyramid_start = time.time()\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m level \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, pyramid_levels):\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     \u001b[43mbuild_level\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdownsample_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_chunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m        \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompressor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTotal pyramid time: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    222\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(time.time()\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mpyramid_start)/\u001b[32m60\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m minutes\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    224\u001b[39m client.close()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 168\u001b[39m, in \u001b[36mbuild_level\u001b[39m\u001b[34m(client, output_path, level, downsample_factor, target_chunks, sigma, compressor, max_in_flight)\u001b[39m\n\u001b[32m    165\u001b[39m             futures.append(future)\n\u001b[32m    167\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(futures) >= max_in_flight:\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m                 \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m                 futures = []\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m futures:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/client.py:5705\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(fs, timeout, return_when)\u001b[39m\n\u001b[32m   5703\u001b[39m     timeout = parse_timedelta(timeout, default=\u001b[33m\"\u001b[39m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   5704\u001b[39m client = default_client()\n\u001b[32m-> \u001b[39m\u001b[32m5705\u001b[39m result = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_wait\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_when\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_when\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5706\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/utils.py:383\u001b[39m, in \u001b[36mSyncMethodMixin.sync\u001b[39m\u001b[34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[39m\n\u001b[32m    381\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m future\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m383\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/utils.py:456\u001b[39m, in \u001b[36msync\u001b[39m\u001b[34m(loop, func, callback_timeout, *args, **kwargs)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    455\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m e.is_set():\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m         \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    459\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/utils.py:445\u001b[39m, in \u001b[36msync.<locals>.wait\u001b[39m\u001b[34m(timeout)\u001b[39m\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwait\u001b[39m(timeout: \u001b[38;5;28mfloat\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    444\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43me\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    446\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m    447\u001b[39m         loop.add_callback(cancel)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/threading.py:655\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    653\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    361\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-12 17:46:31,918 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:62507' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'gaussian_downsample_block-aadce9105eadf808b574a6d1e4e10fd8', 'gaussian_downsample_block-6493f95af51d7b353fe37daad274b029', 'gaussian_downsample_block-03691d3a911ea829f307c3a0341e70a2'} (stimulus_id='handle-worker-cleanup-1770914791.918449')\n",
      "2026-02-12 17:46:31,960 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:62514' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'gaussian_downsample_block-869f76f7d811b3caa3c042e8d9f1a7f1', 'gaussian_downsample_block-9c8bdf28f635ef66ae9698dfb3735d30', 'gaussian_downsample_block-9ae89bc56e8390998a4babe507a8d5e8'} (stimulus_id='handle-worker-cleanup-1770914791.960077')\n",
      "2026-02-12 17:46:31,961 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:62505' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'gaussian_downsample_block-d7077049999e2466e7a2563e0e2a526f', 'gaussian_downsample_block-5dd278024d6f6f9f14b9d0118e64c587', 'gaussian_downsample_block-1f0a2062a18297f74548028f1bd6b7c0'} (stimulus_id='handle-worker-cleanup-1770914791.9609861')\n",
      "2026-02-12 17:46:31,961 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:62525' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'gaussian_downsample_block-c74de2668898695decb4dd017fd3bf38', 'gaussian_downsample_block-d36f3c97bcc423f4bdfc718e86a10666', 'gaussian_downsample_block-656f7fb4d2e9be54a77c0bbb00fcf2d4'} (stimulus_id='handle-worker-cleanup-1770914791.961776')\n",
      "2026-02-12 17:46:33,687 - distributed.nanny - ERROR - Worker process died unexpectedly\n",
      "2026-02-12 17:46:33,688 - distributed.nanny - ERROR - Worker process died unexpectedly\n",
      "Process Dask Worker process (from Nanny):\n",
      "Process Dask Worker process (from Nanny):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/base_events.py\", line 691, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 985, in run\n",
      "    await worker.finished()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/core.py\", line 494, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 1023, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 195, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/base_events.py\", line 691, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 985, in run\n",
      "    await worker.finished()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/core.py\", line 494, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 1023, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 195, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "2026-02-12 17:46:33,709 - distributed.nanny - ERROR - Worker process died unexpectedly\n",
      "2026-02-12 17:46:33,709 - distributed.nanny - ERROR - Worker process died unexpectedly\n",
      "Process Dask Worker process (from Nanny):\n",
      "Process Dask Worker process (from Nanny):\n",
      "Process Dask Worker process (from Nanny):\n",
      "Process Dask Worker process (from Nanny):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/base_events.py\", line 691, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 985, in run\n",
      "    await worker.finished()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/core.py\", line 494, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
      "    await fut\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/base_events.py\", line 691, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "2026-02-12 17:46:33,711 - distributed.nanny - ERROR - Worker process died unexpectedly\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 985, in run\n",
      "    await worker.finished()\n",
      "asyncio.exceptions.CancelledError\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/core.py\", line 494, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
      "    await fut\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Dask Worker process (from Nanny):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 1023, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 195, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 1023, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 195, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/base_events.py\", line 691, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 985, in run\n",
      "    await worker.finished()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/core.py\", line 494, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 1023, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 195, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/base_events.py\", line 691, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 985, in run\n",
      "    await worker.finished()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/core.py\", line 494, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 1023, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 195, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "2026-02-12 17:46:33,713 - distributed.nanny - ERROR - Worker process died unexpectedly\n",
      "Process Dask Worker process (from Nanny):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/base_events.py\", line 691, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 985, in run\n",
      "    await worker.finished()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/core.py\", line 494, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 1023, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 195, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/base_events.py\", line 691, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 985, in run\n",
      "    await worker.finished()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/core.py\", line 494, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 1023, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 195, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "2026-02-12 17:46:33,747 - distributed.nanny - ERROR - Worker process died unexpectedly\n",
      "Process Dask Worker process (from Nanny):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/base_events.py\", line 691, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 985, in run\n",
      "    await worker.finished()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/core.py\", line 494, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 1023, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 195, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "2026-02-12 17:46:33,751 - distributed.nanny - ERROR - Worker process died unexpectedly\n",
      "2026-02-12 17:46:33,752 - distributed.nanny - ERROR - Worker process died unexpectedly\n",
      "Process Dask Worker process (from Nanny):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/base_events.py\", line 691, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 985, in run\n",
      "    await worker.finished()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/core.py\", line 494, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 1023, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 195, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "2026-02-12 17:46:33,757 - distributed.nanny - ERROR - Worker process died unexpectedly\n",
      "2026-02-12 17:46:33,758 - distributed.nanny - ERROR - Worker process died unexpectedly\n",
      "2026-02-12 17:46:33,760 - distributed.nanny - ERROR - Worker process died unexpectedly\n",
      "Process Dask Worker process (from Nanny):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/base_events.py\", line 691, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 985, in run\n",
      "    await worker.finished()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/core.py\", line 494, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 1023, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 195, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "Process Dask Worker process (from Nanny):\n",
      "Process Dask Worker process (from Nanny):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/base_events.py\", line 691, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 985, in run\n",
      "    await worker.finished()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/core.py\", line 494, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 1023, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 195, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "Process Dask Worker process (from Nanny):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/base_events.py\", line 691, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 985, in run\n",
      "    await worker.finished()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/core.py\", line 494, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 1023, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 195, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/base_events.py\", line 691, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 985, in run\n",
      "    await worker.finished()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/core.py\", line 494, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 1023, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 195, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "2026-02-12 17:46:33,790 - distributed.nanny - ERROR - Worker process died unexpectedly\n",
      "Process Dask Worker process (from Nanny):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/base_events.py\", line 691, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 985, in run\n",
      "    await worker.finished()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/core.py\", line 494, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 1023, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 195, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "2026-02-12 17:46:33,803 - distributed.nanny - ERROR - Worker process died unexpectedly\n",
      "Process Dask Worker process (from Nanny):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/base_events.py\", line 691, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 985, in run\n",
      "    await worker.finished()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/core.py\", line 494, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/distributed/nanny.py\", line 1023, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 195, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import zarr\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from dask.distributed import Client, LocalCluster, wait\n",
    "from numcodecs import Blosc\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Worker Task\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def gaussian_downsample_block(\n",
    "    src_path,\n",
    "    dst_path,\n",
    "    src_slices,\n",
    "    dst_slices,\n",
    "    sigma,\n",
    "    downsample_factor,\n",
    "    halo\n",
    "):\n",
    "    \"\"\"\n",
    "    Each task:\n",
    "    - Opens source and destination\n",
    "    - Reads region with halo\n",
    "    - Applies Gaussian blur\n",
    "    - Removes halo\n",
    "    - Subsamples\n",
    "    - Writes output block\n",
    "    \"\"\"\n",
    "\n",
    "    src = zarr.open(src_path, mode=\"r\")\n",
    "    dst = zarr.open(dst_path, mode=\"r+\")\n",
    "\n",
    "    block = src[src_slices]\n",
    "\n",
    "    # Apply Gaussian filter\n",
    "    blurred = gaussian_filter(block, sigma=sigma)\n",
    "\n",
    "    # Remove halo region\n",
    "    z0, z1 = halo[0]\n",
    "    y0, y1 = halo[1]\n",
    "    x0, x1 = halo[2]\n",
    "\n",
    "    core = blurred[\n",
    "        z0:blurred.shape[0]-z1,\n",
    "        y0:blurred.shape[1]-y1,\n",
    "        x0:blurred.shape[2]-x1,\n",
    "    ]\n",
    "\n",
    "    # Trim to divisible by downsample factor\n",
    "    z2 = (core.shape[0] // downsample_factor) * downsample_factor\n",
    "    y2 = (core.shape[1] // downsample_factor) * downsample_factor\n",
    "    x2 = (core.shape[2] // downsample_factor) * downsample_factor\n",
    "\n",
    "    core = core[:z2, :y2, :x2]\n",
    "\n",
    "    # Subsample\n",
    "    down = core[::downsample_factor, ::downsample_factor, ::downsample_factor]\n",
    "\n",
    "    dst[dst_slices] = down\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Build One Level\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def build_level(\n",
    "    client,\n",
    "    output_path,\n",
    "    level,\n",
    "    downsample_factor,\n",
    "    target_chunks,\n",
    "    sigma,\n",
    "    compressor,\n",
    "    max_in_flight=128,\n",
    "):\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"LEVEL {level}: Gaussian Downsampling\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    src_path = os.path.join(output_path, str(level - 1))\n",
    "    dst_path = os.path.join(output_path, str(level))\n",
    "\n",
    "    src = zarr.open(src_path, mode=\"r\")\n",
    "    current_shape = src.shape\n",
    "\n",
    "    new_shape = tuple(max(1, s // downsample_factor) for s in current_shape)\n",
    "\n",
    "    print(f\"Previous shape: {current_shape}\")\n",
    "    print(f\"New shape: {new_shape}\")\n",
    "\n",
    "    # Create destination array\n",
    "    dst = zarr.open(\n",
    "        dst_path,\n",
    "        mode=\"w\",\n",
    "        shape=new_shape,\n",
    "        chunks=target_chunks,\n",
    "        dtype=src.dtype,\n",
    "        compressor=compressor,\n",
    "        dimension_separator=\"/\",\n",
    "    )\n",
    "\n",
    "    halo_width = int(3 * sigma)  # typical Gaussian support\n",
    "\n",
    "    futures = []\n",
    "\n",
    "    level_start = time.time()\n",
    "\n",
    "    chunk_z, chunk_y, chunk_x = target_chunks\n",
    "\n",
    "    for z0 in range(0, new_shape[0], chunk_z):\n",
    "        for y0 in range(0, new_shape[1], chunk_y):\n",
    "            for x0 in range(0, new_shape[2], chunk_x):\n",
    "\n",
    "                dst_slices = (\n",
    "                    slice(z0, min(z0 + chunk_z, new_shape[0])),\n",
    "                    slice(y0, min(y0 + chunk_y, new_shape[1])),\n",
    "                    slice(x0, min(x0 + chunk_x, new_shape[2])),\n",
    "                )\n",
    "\n",
    "                # Compute corresponding source region\n",
    "                src_start = (\n",
    "                    z0 * downsample_factor,\n",
    "                    y0 * downsample_factor,\n",
    "                    x0 * downsample_factor,\n",
    "                )\n",
    "                src_end = (\n",
    "                    min((z0 + chunk_z) * downsample_factor, current_shape[0]),\n",
    "                    min((y0 + chunk_y) * downsample_factor, current_shape[1]),\n",
    "                    min((x0 + chunk_x) * downsample_factor, current_shape[2]),\n",
    "                )\n",
    "\n",
    "                # Add halo\n",
    "                src_slices = []\n",
    "                halo = []\n",
    "\n",
    "                for dim in range(3):\n",
    "                    start = max(0, src_start[dim] - halo_width)\n",
    "                    end = min(current_shape[dim], src_end[dim] + halo_width)\n",
    "\n",
    "                    left_halo = src_start[dim] - start\n",
    "                    right_halo = end - src_end[dim]\n",
    "\n",
    "                    src_slices.append(slice(start, end))\n",
    "                    halo.append((left_halo, right_halo))\n",
    "\n",
    "                future = client.submit(\n",
    "                    gaussian_downsample_block,\n",
    "                    src_path,\n",
    "                    dst_path,\n",
    "                    tuple(src_slices),\n",
    "                    dst_slices,\n",
    "                    sigma,\n",
    "                    downsample_factor,\n",
    "                    tuple(halo),\n",
    "                )\n",
    "\n",
    "                futures.append(future)\n",
    "\n",
    "                if len(futures) >= max_in_flight:\n",
    "                    wait(futures)\n",
    "                    futures = []\n",
    "\n",
    "    if futures:\n",
    "        wait(futures)\n",
    "\n",
    "    print(f\"Finished level {level}\"\n",
    "        f\"{(time.time() - level_start):.1f}s\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Main Pyramid Builder\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "sigma = 1.0\n",
    "\n",
    "cluster = LocalCluster(\n",
    "    n_workers=n_workers,\n",
    "    threads_per_worker=1,\n",
    "    processes=True,\n",
    "    memory_limit=memory_limit,\n",
    ")\n",
    "\n",
    "client = Client(cluster)\n",
    "\n",
    "print(f\"Dask dashboard: {client.dashboard_link}\")\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"Building OME-Zarr Multi-Resolution Pyramid (Gaussian)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "compressor = Blosc(\n",
    "    cname=\"zstd\",\n",
    "    clevel=compression_level,\n",
    "    shuffle=Blosc.BITSHUFFLE,\n",
    ")\n",
    "\n",
    "pyramid_start = time.time()\n",
    "\n",
    "for level in range(1, pyramid_levels):\n",
    "\n",
    "    build_level(\n",
    "        client,\n",
    "        output_path,\n",
    "        level,\n",
    "        downsample_factor,\n",
    "        target_chunks,\n",
    "        sigma,\n",
    "        compressor,\n",
    "    )\n",
    "\n",
    "print(\"\\nTotal pyramid time: \"\n",
    "      f\"{(time.time() - pyramid_start)/60:.2f} minutes\")\n",
    "\n",
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa88a8ef-efc6-4d56-813a-31276a6f4f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 3: Write OME-Zarr Metadata\n",
      "============================================================\n",
      "Adding OME-Zarr Metadata\n",
      "============================================================\n",
      "DONE\n",
      "\n",
      "Pyramid Summary:\n",
      "------------------------------------------------------------\n",
      "  Level 0: shape=(1651, 2200, 2200), chunks=(64, 64, 64), size=31.96 GB\n",
      "  Level 1: shape=(825, 1100, 1100), chunks=(64, 64, 64), size=3.99 GB\n",
      "  Level 2: shape=(412, 550, 550), chunks=(64, 64, 64), size=0.50 GB\n",
      "  Level 3: shape=(206, 275, 275), chunks=(64, 64, 64), size=0.06 GB\n",
      "  Level 4: shape=(103, 137, 137), chunks=(64, 64, 64), size=0.01 GB\n"
     ]
    }
   ],
   "source": [
    "print(\"Stage 3: Write OME-Zarr Metadata\")\n",
    "\n",
    "# ===== ADD OME-ZARR METADATA =====\n",
    "print(f\"{'='*60}\")\n",
    "print(\"Adding OME-Zarr Metadata\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "store = zarr.NestedDirectoryStore(output_path)\n",
    "root = zarr.open_group(store, mode=\"a\")  # append mode\n",
    "\n",
    "# Build datasets list\n",
    "datasets = []\n",
    "for level in range(pyramid_levels):\n",
    "    scale_factor = downsample_factor ** level\n",
    "    datasets.append({\n",
    "        'path': str(level),\n",
    "        'coordinateTransformations': [{\n",
    "            'type': 'scale',\n",
    "            'scale': [\n",
    "                float(scale_factor),  # z\n",
    "                float(scale_factor),  # y\n",
    "                float(scale_factor)   # x\n",
    "            ]\n",
    "        }]\n",
    "    })\n",
    "    \n",
    "# Add multiscales metadata\n",
    "root.attrs['multiscales'] = [{\n",
    "    'version': '0.4',\n",
    "    'name': 'pyramid',\n",
    "    'axes': [\n",
    "        {'name': 'z', 'type': 'space', 'unit': 'micrometer'},\n",
    "        {'name': 'y', 'type': 'space', 'unit': 'micrometer'},\n",
    "        {'name': 'x', 'type': 'space', 'unit': 'micrometer'}\n",
    "    ],\n",
    "    'datasets': datasets,\n",
    "    'type': 'mean',  # Downsampling method\n",
    "    'metadata': {\n",
    "        'description': 'Multi-resolution pyramid',\n",
    "        'method': 'block mean downsampling'\n",
    "    }\n",
    "}]\n",
    "print(\"DONE\")\n",
    "print(\"\\nPyramid Summary:\")\n",
    "print(\"-\" * 60)\n",
    "    \n",
    "for level in range(pyramid_levels):\n",
    "    arr = zarr.open(store, mode='r')[str(level)]\n",
    "    size_gb = np.prod(arr.shape) * arr.dtype.itemsize / 1e9\n",
    "    print(f\"  Level {level}: shape={arr.shape}, chunks={arr.chunks}, size={size_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f9490f-b81d-46a1-81aa-b20f2102816d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
