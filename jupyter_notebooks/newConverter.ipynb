{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDF5 to Multi-resolution Zarr Pyramid\n",
    "\n",
    "This notebook converts HDF5 data to a multi-resolution Zarr pyramid with optimal chunking.\n",
    "\n",
    "**Pipeline:**\n",
    "1. Convert HDF5 → Zarr\n",
    "2. Rechunk to (64, 64, 64) using rechunker\n",
    "3. Generate pyramid levels 1-4 (level 0 already exists from rechunking)\n",
    "4. Add OME-Zarr metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Packages\n",
    "\n",
    "Uncomment and run if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rechunker scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import zarr\n",
    "import numpy as np\n",
    "from rechunker import rechunk\n",
    "import dask.array as da\n",
    "from skimage.transform import downscale_local_mean\n",
    "import tempfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set your input/output paths and parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "HDF5_PATH = \"your_data.h5\"              # Path to your HDF5 file\n",
    "DATASET_NAME = \"/data\"                  # HDF5 dataset name (e.g., '/data', '/images/stack')\n",
    "OUTPUT_ZARR_PATH = \"output_pyramid.zarr\"  # Output Zarr path\n",
    "CHUNK_SIZE = (64, 64, 64)               # Chunk size for all levels\n",
    "N_LEVELS = 5                            # Number of pyramid levels\n",
    "DOWNSCALE_FACTOR = 2                    # Downsampling factor between levels\n",
    "MAX_MEMORY = \"2GB\"                      # Memory limit for rechunker\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Input: {HDF5_PATH}\")\n",
    "print(f\"  Output: {OUTPUT_ZARR_PATH}\")\n",
    "print(f\"  Chunk size: {CHUNK_SIZE}\")\n",
    "print(f\"  Pyramid levels: {N_LEVELS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Convert HDF5 to Temporary Zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 1: Converting HDF5 to Zarr...\")\n",
    "\n",
    "# Open HDF5 and inspect\n",
    "with h5py.File(HDF5_PATH, 'r') as f:\n",
    "    dset = f[DATASET_NAME]\n",
    "    shape = dset.shape\n",
    "    dtype = dset.dtype\n",
    "    \n",
    "    print(f\"  Dataset shape: {shape}\")\n",
    "    print(f\"  Dataset dtype: {dtype}\")\n",
    "    \n",
    "    # Create temporary Zarr for initial conversion\n",
    "    temp_zarr = tempfile.mkdtemp(prefix='temp_zarr_')\n",
    "    temp_store = zarr.open(temp_zarr, mode='w')\n",
    "    temp_array = temp_store.create_dataset(\n",
    "        'data',\n",
    "        shape=shape,\n",
    "        dtype=dtype,\n",
    "        chunks=CHUNK_SIZE\n",
    "    )\n",
    "    \n",
    "    # Copy data in chunks to avoid memory issues\n",
    "    print(\"  Copying data...\")\n",
    "    for i in range(0, shape[0], CHUNK_SIZE[0]):\n",
    "        for j in range(0, shape[1], CHUNK_SIZE[1]):\n",
    "            for k in range(0, shape[2], CHUNK_SIZE[2]):\n",
    "                i_end = min(i + CHUNK_SIZE[0], shape[0])\n",
    "                j_end = min(j + CHUNK_SIZE[1], shape[1])\n",
    "                k_end = min(k + CHUNK_SIZE[2], shape[2])\n",
    "                temp_array[i:i_end, j:j_end, k:k_end] = \\\n",
    "                    dset[i:i_end, j:j_end, k:k_end]\n",
    "        print(f\"    Progress: {min(i + CHUNK_SIZE[0], shape[0])}/{shape[0]} slices\")\n",
    "\n",
    "print(\"  ✓ Conversion complete\")\n",
    "print(f\"  Temporary Zarr: {temp_zarr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Rechunk Using Rechunker\n",
    "\n",
    "This creates level 0 of the pyramid with optimal chunking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 2: Rechunking with rechunker...\")\n",
    "\n",
    "# Load source array\n",
    "source_array = da.from_zarr(temp_zarr, component='data')\n",
    "print(f\"  Source array shape: {source_array.shape}\")\n",
    "print(f\"  Source chunks: {source_array.chunksize}\")\n",
    "\n",
    "# Create output store\n",
    "output_store = zarr.open(OUTPUT_ZARR_PATH, mode='w')\n",
    "\n",
    "# Setup rechunker\n",
    "temp_rechunk = tempfile.mkdtemp(prefix='temp_rechunk_')\n",
    "print(f\"  Target chunks: {CHUNK_SIZE}\")\n",
    "print(f\"  Max memory: {MAX_MEMORY}\")\n",
    "\n",
    "rechunked = rechunk(\n",
    "    source_array,\n",
    "    target_chunks=CHUNK_SIZE,\n",
    "    max_mem=MAX_MEMORY,\n",
    "    target_store=OUTPUT_ZARR_PATH + '/0',\n",
    "    temp_store=temp_rechunk\n",
    ")\n",
    "\n",
    "# Execute rechunking\n",
    "print(\"  Executing rechunk (this may take a while)...\")\n",
    "rechunked.execute()\n",
    "\n",
    "print(\"  ✓ Rechunking complete\")\n",
    "print(f\"  Level 0 created at: {OUTPUT_ZARR_PATH}/0\")\n",
    "\n",
    "# Clean up temporary stores\n",
    "shutil.rmtree(temp_zarr)\n",
    "shutil.rmtree(temp_rechunk)\n",
    "print(\"  ✓ Temporary files cleaned up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate Pyramid Levels\n",
    "\n",
    "Create downsampled levels 1-4 (level 0 already exists):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Step 3: Generating pyramid levels 1-{N_LEVELS-1}...\")\n",
    "\n",
    "output_store = zarr.open(OUTPUT_ZARR_PATH, mode='a')\n",
    "previous_level = output_store['0']\n",
    "\n",
    "for level in range(1, N_LEVELS):\n",
    "    print(f\"\\n  Creating level {level}...\")\n",
    "    \n",
    "    # Calculate new shape\n",
    "    factor = DOWNSCALE_FACTOR ** level\n",
    "    new_shape = tuple(s // factor for s in shape)\n",
    "    print(f\"    Target shape: {new_shape}\")\n",
    "    print(f\"    Downscale factor: {factor}x\")\n",
    "    \n",
    "    # Load data from previous level\n",
    "    data = previous_level[:]\n",
    "    print(f\"    Loaded data shape: {data.shape}\")\n",
    "    \n",
    "    # Perform downsampling\n",
    "    scale_factors = (DOWNSCALE_FACTOR,) * len(shape)\n",
    "    print(f\"    Downsampling...\")\n",
    "    downsampled = downscale_local_mean(data, scale_factors)\n",
    "    print(f\"    Downsampled shape: {downsampled.shape}\")\n",
    "    \n",
    "    # Create new level\n",
    "    output_store.create_dataset(\n",
    "        str(level),\n",
    "        data=downsampled,\n",
    "        chunks=CHUNK_SIZE,\n",
    "        dtype=dtype,\n",
    "        overwrite=True\n",
    "    )\n",
    "    \n",
    "    previous_level = output_store[str(level)]\n",
    "    print(f\"    ✓ Level {level} created\")\n",
    "\n",
    "print(f\"\\n  ✓ All pyramid levels generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Add OME-Zarr Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 4: Adding OME-Zarr metadata...\")\n",
    "\n",
    "# Create multiscales metadata\n",
    "datasets = []\n",
    "for level in range(N_LEVELS):\n",
    "    factor = DOWNSCALE_FACTOR ** level\n",
    "    datasets.append({\n",
    "        \"path\": str(level),\n",
    "        \"coordinateTransformations\": [{\n",
    "            \"type\": \"scale\",\n",
    "            \"scale\": [factor, factor, factor]\n",
    "        }]\n",
    "    })\n",
    "\n",
    "multiscales = [{\n",
    "    \"version\": \"0.4\",\n",
    "    \"name\": \"pyramid\",\n",
    "    \"axes\": [\n",
    "        {\"name\": \"z\", \"type\": \"space\", \"unit\": \"micrometer\"},\n",
    "        {\"name\": \"y\", \"type\": \"space\", \"unit\": \"micrometer\"},\n",
    "        {\"name\": \"x\", \"type\": \"space\", \"unit\": \"micrometer\"}\n",
    "    ],\n",
    "    \"datasets\": datasets,\n",
    "    \"type\": \"gaussian\",\n",
    "    \"metadata\": {\n",
    "        \"description\": \"Multi-resolution pyramid\",\n",
    "        \"method\": \"skimage.transform.downscale_local_mean\"\n",
    "    }\n",
    "}]\n",
    "\n",
    "output_store.attrs['multiscales'] = multiscales\n",
    "print(\"  ✓ OME-Zarr metadata added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification\n",
    "\n",
    "Verify the pyramid structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PYRAMID CREATED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "store = zarr.open(OUTPUT_ZARR_PATH, mode='r')\n",
    "\n",
    "print(f\"\\nOutput location: {OUTPUT_ZARR_PATH}\")\n",
    "print(f\"\\nPyramid structure:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for level in range(N_LEVELS):\n",
    "    if str(level) in store:\n",
    "        arr = store[str(level)]\n",
    "        factor = DOWNSCALE_FACTOR ** level\n",
    "        memory_mb = np.prod(arr.shape) * arr.dtype.itemsize / (1024**2)\n",
    "        print(f\"Level {level}:\")\n",
    "        print(f\"  Shape:  {arr.shape}\")\n",
    "        print(f\"  Chunks: {arr.chunks}\")\n",
    "        print(f\"  Factor: {factor}x downsampled\")\n",
    "        print(f\"  Memory: {memory_mb:.2f} MB\")\n",
    "        print()\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(\"\\nTo view in napari:\")\n",
    "print(f\"  napari --plugin napari-ome-zarr {OUTPUT_ZARR_PATH}\")\n",
    "print(\"\\nOr in Python:\")\n",
    "print(f\"  import napari\")\n",
    "print(f\"  viewer = napari.Viewer()\")\n",
    "print(f\"  viewer.open('{OUTPUT_ZARR_PATH}', plugin='napari-ome-zarr')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Quick Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect a middle slice from each level\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, N_LEVELS, figsize=(15, 3))\n",
    "fig.suptitle('Middle Z-slice from each pyramid level')\n",
    "\n",
    "for level in range(N_LEVELS):\n",
    "    arr = store[str(level)]\n",
    "    mid_slice = arr[arr.shape[0]//2, :, :]\n",
    "    \n",
    "    axes[level].imshow(mid_slice, cmap='gray')\n",
    "    axes[level].set_title(f'Level {level}\\n{arr.shape}')\n",
    "    axes[level].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
