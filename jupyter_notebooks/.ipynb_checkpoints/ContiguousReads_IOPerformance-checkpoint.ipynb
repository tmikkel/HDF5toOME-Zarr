{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b7f60d-33fe-4946-8a89-e7861ed912a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requires Zarr version less than 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf989794-5d76-4844-847c-a25030704e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported succesfully!\n",
      "2.18.7\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import zarr\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import dask\n",
    "import dask.array as da\n",
    "from dask.diagnostics import ProgressBar\n",
    "import numpy as np\n",
    "from numcodecs import Blosc\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"All libraries imported succesfully!\")\n",
    "print(zarr.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0ce794f-8f79-4e79-8e0c-493caf3f36c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion arguments\n",
    "#input_path = \"/dtu/3d-imaging-center/projects/2023_CoM-BraiN/analysis/OME_Output/small_wMB_4bin.h5\"\n",
    "#output_path = \"/dtu/3d-imaging-center/projects/2023_CoM-BraiN/analysis/OME_Output/contiguous_test1.ome.zarr\"\n",
    "input_path = \"/Users/tobiasschleiss/documents/dtu/thesis/input/new_small_wMB_4bin.h5\"\n",
    "output_path = \"/Users/tobiasschleiss/Documents/DTU/Thesis/output/contiguous_test1.ome.zarr\"\n",
    "\n",
    "target_chunks = (64, 64, 64)\n",
    "dataset_path = 'exchange/data'\n",
    "compression_level=3\n",
    "\n",
    "no_seeks = True\n",
    "\n",
    "if no_seeks == False:\n",
    "    block_shape = (64, 2200, 2200) #Approximatly 1.2GB with no disk seeks\n",
    "else:\n",
    "    block_shape = (640, 640, 640) #Approximatly 1GB with many disk seeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11832fc6-e369-4de0-9135-373751944554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Shape: (1651, 2200, 2200)\n",
      "  Dtype: float32\n",
      "  Size: 29.77 GB\n"
     ]
    }
   ],
   "source": [
    "# Inspect HDF5 file\n",
    "with h5py.File(input_path, 'r') as f:\n",
    "    if dataset_path not in f:\n",
    "        print(f\"  ERROR: Dataset '{dataset_path}' not found\")\n",
    "        print(f\"  Available paths: {list(f.keys())}\")\n",
    "        \n",
    "    dataset = f[dataset_path]\n",
    "    shape = dataset.shape\n",
    "    dtype = dataset.dtype\n",
    "    data_size_gb = dataset.nbytes / (1024**3)\n",
    "    dtype_size = dtype.itemsize\n",
    "        \n",
    "    print(f\"  Shape: {shape}\")\n",
    "    print(f\"  Dtype: {dtype}\")\n",
    "    print(f\"  Size: {data_size_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9128d45f-05f1-42fc-8d87-41ae950009cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1: HDF5 -> Level 0 zarr (optimized for contigous reads)\n",
      "Selected block shape: (640, 640, 640)\n",
      "Processing 48 blocks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/zbsy0qhn18sfk0qmktm5qs3h0000gn/T/ipykernel_30191/2102984051.py:14: FutureWarning: The NestedDirectoryStore is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "  store = zarr.NestedDirectoryStore(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Block    1/48 (  2.1%) -   0.3 blocks/s - ETA:    149s\n",
      "  Block    2/48 (  4.2%) -   0.4 blocks/s - ETA:    107s\n",
      "  Block    3/48 (  6.2%) -   0.5 blocks/s - ETA:     90s\n",
      "  Block    4/48 (  8.3%) -   0.6 blocks/s - ETA:     75s\n",
      "  Block    5/48 ( 10.4%) -   0.5 blocks/s - ETA:     88s\n",
      "  Block    6/48 ( 12.5%) -   0.5 blocks/s - ETA:     83s\n",
      "  Block    7/48 ( 14.6%) -   0.5 blocks/s - ETA:     77s\n",
      "  Block    8/48 ( 16.7%) -   0.6 blocks/s - ETA:     69s\n",
      "  Block    9/48 ( 18.8%) -   0.5 blocks/s - ETA:     75s\n",
      "  Block   10/48 ( 20.8%) -   0.5 blocks/s - ETA:     71s\n",
      "  Block   11/48 ( 22.9%) -   0.5 blocks/s - ETA:     68s\n",
      "  Block   12/48 ( 25.0%) -   0.6 blocks/s - ETA:     63s\n",
      "  Block   13/48 ( 27.1%) -   0.6 blocks/s - ETA:     61s\n",
      "  Block   14/48 ( 29.2%) -   0.6 blocks/s - ETA:     56s\n",
      "  Block   15/48 ( 31.2%) -   0.6 blocks/s - ETA:     52s\n",
      "  Block   16/48 ( 33.3%) -   0.7 blocks/s - ETA:     48s\n",
      "  Block   17/48 ( 35.4%) -   0.6 blocks/s - ETA:     50s\n",
      "  Block   18/48 ( 37.5%) -   0.6 blocks/s - ETA:     48s\n",
      "  Block   19/48 ( 39.6%) -   0.6 blocks/s - ETA:     46s\n",
      "  Block   20/48 ( 41.7%) -   0.6 blocks/s - ETA:     44s\n",
      "  Block   21/48 ( 43.8%) -   0.6 blocks/s - ETA:     44s\n",
      "  Block   22/48 ( 45.8%) -   0.6 blocks/s - ETA:     43s\n",
      "  Block   23/48 ( 47.9%) -   0.6 blocks/s - ETA:     41s\n",
      "  Block   24/48 ( 50.0%) -   0.6 blocks/s - ETA:     38s\n",
      "  Block   25/48 ( 52.1%) -   0.6 blocks/s - ETA:     38s\n",
      "  Block   26/48 ( 54.2%) -   0.6 blocks/s - ETA:     36s\n",
      "  Block   27/48 ( 56.2%) -   0.6 blocks/s - ETA:     34s\n",
      "  Block   28/48 ( 58.3%) -   0.6 blocks/s - ETA:     32s\n",
      "  Block   29/48 ( 60.4%) -   0.6 blocks/s - ETA:     31s\n",
      "  Block   30/48 ( 62.5%) -   0.6 blocks/s - ETA:     28s\n",
      "  Block   31/48 ( 64.6%) -   0.6 blocks/s - ETA:     26s\n",
      "  Block   32/48 ( 66.7%) -   0.7 blocks/s - ETA:     24s\n",
      "  Block   33/48 ( 68.8%) -   0.7 blocks/s - ETA:     23s\n",
      "  Block   34/48 ( 70.8%) -   0.7 blocks/s - ETA:     21s\n",
      "  Block   35/48 ( 72.9%) -   0.7 blocks/s - ETA:     19s\n",
      "  Block   36/48 ( 75.0%) -   0.7 blocks/s - ETA:     17s\n",
      "  Block   37/48 ( 77.1%) -   0.7 blocks/s - ETA:     16s\n",
      "  Block   38/48 ( 79.2%) -   0.7 blocks/s - ETA:     14s\n",
      "  Block   39/48 ( 81.2%) -   0.7 blocks/s - ETA:     13s\n",
      "  Block   40/48 ( 83.3%) -   0.7 blocks/s - ETA:     11s\n",
      "  Block   41/48 ( 85.4%) -   0.7 blocks/s - ETA:     10s\n",
      "  Block   42/48 ( 87.5%) -   0.7 blocks/s - ETA:      8s\n",
      "  Block   43/48 ( 89.6%) -   0.7 blocks/s - ETA:      7s\n",
      "  Block   44/48 ( 91.7%) -   0.7 blocks/s - ETA:      5s\n",
      "  Block   45/48 ( 93.8%) -   0.7 blocks/s - ETA:      4s\n",
      "  Block   46/48 ( 95.8%) -   0.7 blocks/s - ETA:      3s\n",
      "  Block   47/48 ( 97.9%) -   0.8 blocks/s - ETA:      1s\n",
      "  Block   48/48 (100.0%) -   0.8 blocks/s - ETA:      0s\n",
      "\n",
      "✓ Level 0 complete in 62.3s\n",
      "  0:01:02\n",
      "  Throughput: 0.51 GB/s\n"
     ]
    }
   ],
   "source": [
    "print(\"Stage 1: HDF5 -> Level 0 zarr (optimized for contigous reads)\")\n",
    "\n",
    "# Open HDF5\n",
    "with h5py.File(input_path, 'r') as f:\n",
    "    dataset = f[dataset_path]\n",
    "    shape = dataset.shape\n",
    "    dtype = dataset.dtype \n",
    "\n",
    "    block_z, block_y, block_x = block_shape\n",
    "    print(f\"Selected block shape: {block_shape}\")\n",
    "    z_total, y_total, x_total = shape\n",
    "        \n",
    "    # Setup output zarr store    \n",
    "    store = zarr.NestedDirectoryStore(output_path)\n",
    "    root = zarr.open_group(store=store, mode='w')\n",
    "\n",
    "    # Compressor for all levels\n",
    "    compressor = Blosc(cname='zstd', clevel=compression_level, shuffle=Blosc.BITSHUFFLE)\n",
    "        \n",
    "    level_0 = root.create_dataset(\n",
    "        '0',\n",
    "        shape=shape,\n",
    "        chunks=target_chunks,\n",
    "        dtype=dtype,\n",
    "        compressor=compressor\n",
    "    )\n",
    "\n",
    "    level0_start = time.time()\n",
    "    block_count = 0\n",
    "        \n",
    "    # Calculate total blocks\n",
    "    total_blocks = (\n",
    "        ((z_total + block_z - 1) // block_z) *\n",
    "        ((y_total + block_y - 1) // block_y) *\n",
    "        ((x_total + block_x - 1) // block_x)\n",
    "    )\n",
    "        \n",
    "    print(f\"Processing {total_blocks} blocks...\")\n",
    "\n",
    "    # Iterate over dataset\n",
    "    for z_start in range(0, z_total, block_z):\n",
    "        z_end = min(z_start + block_z, z_total)\n",
    "            \n",
    "        for y_start in range(0, y_total, block_y):\n",
    "            y_end = min(y_start + block_y, y_total)\n",
    "\n",
    "            for x_start in range(0, x_total, block_x):\n",
    "                x_end = min(x_start + block_x, x_total)\n",
    "                    \n",
    "                block_count += 1\n",
    "                        \n",
    "                # Read block from HDF5\n",
    "                block = dataset[z_start:z_end, y_start:y_end, x_start:x_end]\n",
    "                        \n",
    "                # Write to zarr (zarr will internally chunk to target_chunks)\n",
    "                level_0[z_start:z_end, y_start:y_end, x_start:x_end] = block\n",
    "                        \n",
    "                del block\n",
    "                        \n",
    "                # Progress reporting\n",
    "                if block_count % 1 == 0 or block_count == total_blocks:\n",
    "                    elapsed = time.time() - level0_start\n",
    "                    rate = block_count / elapsed if elapsed > 0 else 0\n",
    "                    eta = (total_blocks - block_count) / rate if rate > 0 else 0\n",
    "                    progress = block_count / total_blocks * 100\n",
    "                        \n",
    "                    print(f\"  Block {block_count:4d}/{total_blocks} ({progress:5.1f}%) - \"\n",
    "                            f\"{rate:5.1f} blocks/s - ETA: {eta:6.0f}s\")   \n",
    "        \n",
    "    elapsed_level0 = time.time() - level0_start\n",
    "    throughput = (np.prod(shape) * dtype_size / 1e9) / elapsed\n",
    "        \n",
    "    print(f\"\\n✓ Level 0 complete in {elapsed_level0:.1f}s\")\n",
    "    print(f\"  {timedelta(seconds=int(elapsed_level0))}\")\n",
    "    print(f\"  Throughput: {throughput:.2f} GB/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5731b4-ab57-4337-80e7-75be77913c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
