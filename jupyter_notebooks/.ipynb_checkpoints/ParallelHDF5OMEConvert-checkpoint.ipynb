{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95da8e8d-b7a4-43de-9673-8fc754ecc160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported succesfully!\n",
      "2.18.7\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import zarr\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from numcodecs import Blosc\n",
    "import dask\n",
    "from dask.distributed import Client, LocalCluster, progress\n",
    "from dask.diagnostics import ProgressBar\n",
    "import dask.array as da\n",
    "from pathlib import Path\n",
    "from math import ceil\n",
    "\n",
    "print(\"All libraries imported succesfully!\")\n",
    "print(zarr.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba224392-20aa-4735-b11e-a19ae01c8889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion arguments\n",
    "\n",
    "input_path = \"/Users/tobiasschleiss/documents/dtu/thesis/input/brain_2bin_cropSmall.h5\"\n",
    "output_path = \"/Users/tobiasschleiss/Documents/DTU/Thesis/output/parallel.ome.zarr\"\n",
    "target_chunks = (64, 64, 64)\n",
    "dataset_path = 'exchange/data'\n",
    "max_mem_gb=32\n",
    "safety_factor=0.7\n",
    "pyramid_levels = 5\n",
    "downsample_factor=2\n",
    "compression_level=3\n",
    "target_top_level_mb=10\n",
    "\n",
    "n_workers = 4\n",
    "threads_per_worker=1\n",
    "memory_limit = \"6GB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc21c60a-0afd-4968-903f-d9d8feb8718e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dask dashboard: http://127.0.0.1:8787/status\n",
      "Dataset shape: (150, 3768, 2008), dtype=float32\n",
      "(512, 512, 512)\n",
      "Rechunking...\n",
      "\n",
      "✓ Done in 7.2s\n",
      "✓ Throughput: 0.63 GB/s\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# CLUSTER\n",
    "# =========================\n",
    "cluster = LocalCluster(\n",
    "    n_workers=n_workers,\n",
    "    threads_per_worker=threads_per_worker,\n",
    "    processes=True,\n",
    "    memory_limit=memory_limit,\n",
    "    dashboard_address=\":8787\",\n",
    ")\n",
    "client = Client(cluster)\n",
    "print(f\"✓ Dask dashboard: {client.dashboard_link}\")\n",
    "\n",
    "# =========================\n",
    "# OPEN HDF5\n",
    "# =========================\n",
    "h5 = h5py.File(input_path, \"r\")\n",
    "dset = h5[dataset_path]\n",
    "shape = dset.shape\n",
    "\n",
    "print(f\"Dataset shape: {shape}, dtype={dset.dtype}\")\n",
    "\n",
    "read_chunks = (512, 512, 512)\n",
    "\n",
    "print(read_chunks)\n",
    "\n",
    "# =========================\n",
    "# DASK ARRAY\n",
    "# =========================\n",
    "darr = da.from_array(\n",
    "    dset,\n",
    "    chunks=read_chunks,\n",
    "    lock=True  # h5py is not thread-safe\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# RECHUNK (single stage)\n",
    "# =========================\n",
    "print(\"Rechunking...\")\n",
    "darr = darr.rechunk(target_chunks)\n",
    "\n",
    "# =========================\n",
    "# WRITE ZARR\n",
    "# =========================\n",
    "compressor = Blosc(\n",
    "    cname=\"zstd\",\n",
    "    clevel=compression_level,\n",
    "    shuffle=Blosc.BITSHUFFLE\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "with ProgressBar():\n",
    "    darr.to_zarr(\n",
    "        output_path,\n",
    "        component=\"0\",\n",
    "        compressor=compressor,\n",
    "        overwrite=True,\n",
    "        dimension_separator=\"/\"\n",
    "    )\n",
    "\n",
    "elapsed = time.time() - start\n",
    "total_gb = np.prod(dset.shape) * dset.dtype.itemsize / 1e9\n",
    "\n",
    "print(f\"\\n✓ Done in {elapsed:.1f}s\")\n",
    "print(f\"✓ Throughput: {total_gb / elapsed:.2f} GB/s\")\n",
    "\n",
    "# =========================\n",
    "# CLEANUP\n",
    "# =========================\n",
    "h5.close()\n",
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87fd05f6-0756-419c-b885-f4e54aeb4271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Source chunks: (64, 64, 64)\n",
      "  Source shape: (150, 3768, 2008)\n"
     ]
    }
   ],
   "source": [
    "# Inspection level_0\n",
    "source = da.from_zarr(output_path, component='0')\n",
    "    \n",
    "print(f\"  Source chunks: {source.chunksize}\")\n",
    "print(f\"  Source shape: {source.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
