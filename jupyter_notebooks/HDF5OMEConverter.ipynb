{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d43c64a6-6350-4e83-b5e5-f65cb0579d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported succesfully!\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import zarr\n",
    "import time\n",
    "import dask.array as da\n",
    "from numcodecs import Blosc\n",
    "from pathlib import Path\n",
    "from ome_zarr.io import parse_url\n",
    "from ome_zarr.writer import write_multiscale\n",
    "\n",
    "print(\"All libraries imported succesfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "817a2c10-f80f-403f-9fc1-025a76d8bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion arguments\n",
    "\n",
    "input_path = \"/Users/tobiasschleiss/documents/dtu/thesis/input/brain_2bin_cropSmall.h5\"\n",
    "output_path = \"/Users/tobiasschleiss/Documents/DTU/Thesis/output/output.ome.zarr\"\n",
    "target_chunks = (64, 64, 64)\n",
    "dataset_path = 'exchange/data'\n",
    "temp_chunk_size=(64, 512, 512)\n",
    "max_mem_gb=12.4\n",
    "pyramid_levels = 5\n",
    "\n",
    "n_workers = 2\n",
    "worker_mem = 4 # memory per wroker in GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71a5e605-a777-454b-b1b6-a4fc3d57403c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Shape: (150, 3768, 2008)\n",
      "  Dtype: float32\n",
      "  Size: 4.23 GB\n",
      "  HDF5 chunks: Contiguous\n"
     ]
    }
   ],
   "source": [
    "# Inspect HDF5 file\n",
    "with h5py.File(input_path, 'r') as f:\n",
    "    if dataset_path not in f:\n",
    "        print(f\"  ERROR: Dataset '{dataset_path}' not found\")\n",
    "        print(f\"  Available paths: {list(f.keys())}\")\n",
    "        \n",
    "    dataset = f[dataset_path]\n",
    "    shape = dataset.shape\n",
    "    dtype = dataset.dtype\n",
    "    h5_chunks = dataset.chunks\n",
    "    data_size_gb = dataset.nbytes / (1024**3)\n",
    "    dtype_size = dtype.itemsize\n",
    "        \n",
    "    print(f\"  Shape: {shape}\")\n",
    "    print(f\"  Dtype: {dtype}\")\n",
    "    print(f\"  Size: {data_size_gb:.2f} GB\")\n",
    "    print(f\"  HDF5 chunks: {h5_chunks if h5_chunks else 'Contiguous'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2497f95d-ac08-4791-be03-2d881cc96b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1: HDF5 -> Temporary Zarr (optimized for sequential reads)\n",
      "/Users/tobiasschleiss/Documents/DTU/Thesis/output/temp_rechunk.zarr\n",
      "  Source shape: (150, 3768, 2008), dtype: float32\n",
      "  Reading Z 0-64\n",
      "  Reading Z 64-128\n",
      "  Reading Z 128-150\n",
      "\n",
      "Timing breakdown:\n",
      "  Writing: 3.3s\n"
     ]
    }
   ],
   "source": [
    "print(\"Stage 1: HDF5 -> Temporary Zarr (optimized for sequential reads)\")\n",
    "    \n",
    "temp_path = Path(output_path).parent / \"temp_rechunk.zarr\"\n",
    "print(temp_path)\n",
    "    \n",
    "# Open HDF5\n",
    "with h5py.File(input_path, 'r') as f:\n",
    "    dataset = f[dataset_path]\n",
    "    shape = dataset.shape\n",
    "    dtype = dataset.dtype\n",
    "        \n",
    "    print(f\"  Source shape: {shape}, dtype: {dtype}\")\n",
    "        \n",
    "    # Create temporary zarr with chunks optimized for reading from contiguous HDF5\n",
    "    temp_store = zarr.DirectoryStore(temp_path)\n",
    "    temp_root = zarr.open_group(temp_store, mode='w')\n",
    "        \n",
    "    temp_array = temp_root.create_dataset(\n",
    "        'data',\n",
    "        shape=shape,\n",
    "        chunks=temp_chunk_size,  # Large Z-slabs\n",
    "        dtype=dtype,\n",
    "        compressor=Blosc(cname='lz4', clevel=1)  # Fast compression for temp\n",
    "    )\n",
    "        \n",
    "    # Copy in large slabs (efficient for contiguous HDF5)\n",
    "\n",
    "    temp_start = time.time()\n",
    "    \n",
    "    slab_size = temp_chunk_size[0]\n",
    "    for z_start in range(0, shape[0], slab_size):\n",
    "        z_end = min(z_start + slab_size, shape[0])\n",
    "        print(f\"  Reading Z planes {z_start}-{z_end}\")\n",
    "            \n",
    "        slab = dataset[z_start:z_end, :, :]\n",
    "        temp_array[z_start:z_end, :, :] = slab\n",
    "        del slab\n",
    "\n",
    "    temp_time = time.time() - temp_start\n",
    "\n",
    "    print(f\"\\nTiming breakdown:\")\n",
    "    print(f\"  Writing: {temp_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8a3eb80-abf9-4eec-a60a-19aa76a25f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stage 2: Temporary Zarr -> Final Zarr (target chunks)\n",
      "  Source chunks: (64, 512, 512)\n",
      "  Target chunks: (64, 64, 64)\n",
      "  Reading from Zarr...\n",
      "  Source chunks: (64, 512, 512)\n",
      "  Target chunks: (64, 64, 64)\n",
      "  Creating 5-level pyramid...\n",
      "Writing OME-Zarr...\n",
      "\n",
      "✓ Conversion complete!\n",
      "  Output: /Users/tobiasschleiss/Documents/DTU/Thesis/output/output.ome.zarr\n",
      "\n",
      "Timing breakdown:\n",
      "  Writing: 7.8s\n",
      "  Output size: 1.76 GB\n",
      "  Write speed: 229.0 MB/s\n",
      "Temporary files cleaned up\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStage 2: Temporary Zarr -> Final Zarr (target chunks)\")\n",
    "\n",
    "# Write to final location\n",
    "compressor = Blosc(cname='zstd', clevel=3, shuffle=Blosc.BITSHUFFLE)\n",
    "\n",
    "try:\n",
    "    print(f\"  Reading from Zarr...\")\n",
    "    data = da.from_zarr(temp_path, component='data')\n",
    "    print(f\"  Source chunks: {data.chunksize}\")\n",
    "    print(f\"  Target chunks: {target_chunks}\")\n",
    "\n",
    "    # Create pyramid\n",
    "    pyramid = [data]\n",
    "    print(f\"  Creating {pyramid_levels}-level pyramid...\")\n",
    "    for i in range(1, pyramid_levels):\n",
    "        pyramid.append(pyramid[-1][::2, ::2, ::2])\n",
    "            \n",
    "    # Write OME-Zarr\n",
    "    print(\"Writing OME-Zarr...\")\n",
    "    write_start = time.time()\n",
    "        \n",
    "    store = parse_url(output_path, mode='w').store\n",
    "    root = zarr.group(store=store)\n",
    "            \n",
    "    write_multiscale(\n",
    "        pyramid=pyramid,\n",
    "        group=root,\n",
    "        axes=\"zyx\",\n",
    "        storage_options={\n",
    "            'chunks': target_chunks,\n",
    "        },\n",
    "        compute=True\n",
    "    )\n",
    "        \n",
    "\n",
    "    write_time = time.time() - write_start\n",
    "            \n",
    "    print(f\"\\n✓ Conversion complete!\")\n",
    "    print(f\"  Output: {output_path}\")\n",
    "         \n",
    "    print(f\"\\nTiming breakdown:\")\n",
    "    print(f\"  Writing: {write_time:.1f}s\")\n",
    "            \n",
    "    # Show output size\n",
    "    if Path(output_path).exists():\n",
    "        output_size_gb = sum(f.stat().st_size for f in Path(output_path).rglob('*') if f.is_file()) / (1024**3)\n",
    "        write_speed_mbps = (output_size_gb * 1024) / write_time if write_time > 0 else 0\n",
    "        print(f\"  Output size: {output_size_gb:.2f} GB\")\n",
    "        print(f\"  Write speed: {write_speed_mbps:.1f} MB/s\")\n",
    "\n",
    "    # Cleanup temp\n",
    "    import shutil\n",
    "    shutil.rmtree(temp_path)\n",
    "    print(\"Temporary files cleaned up\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n✗ Error during conversion: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb2ef653-6a03-40f5-bca8-8d772d916b0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "shape is None",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Inspection of temp data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m source = \u001b[43mda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_zarr\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/Users/tobiasschleiss/Documents/DTU/Thesis/output/temp_rechunk.zarr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Source chunks: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource.chunksize\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Source shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/dask/array/core.py:3802\u001b[39m, in \u001b[36mfrom_zarr\u001b[39m\u001b[34m(url, component, storage_options, chunks, name, inline_array, **kwargs)\u001b[39m\n\u001b[32m   3800\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3801\u001b[39m         store = url\n\u001b[32m-> \u001b[39m\u001b[32m3802\u001b[39m     z = \u001b[43mzarr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3803\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3804\u001b[39m     z = zarr.open_array(store=url, path=component, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/zarr/creation.py:645\u001b[39m, in \u001b[36mopen_array\u001b[39m\u001b[34m(store, mode, shape, chunks, dtype, compressor, fill_value, order, synchronizer, filters, cache_metadata, cache_attrs, path, object_codec, chunk_store, storage_options, partial_decompress, write_empty_chunks, zarr_version, dimension_separator, meta_array, **kwargs)\u001b[39m\n\u001b[32m    643\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m contains_group(store, path=path):\n\u001b[32m    644\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m ContainsGroupError(path)\n\u001b[32m--> \u001b[39m\u001b[32m645\u001b[39m         \u001b[43minit_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m            \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompressor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompressor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m            \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m            \u001b[49m\u001b[43mobject_codec\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobject_codec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchunk_store\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdimension_separator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdimension_separator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mw-\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    661\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m contains_group(store, path=path):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/zarr/storage.py:455\u001b[39m, in \u001b[36minit_array\u001b[39m\u001b[34m(store, shape, chunks, dtype, compressor, fill_value, order, overwrite, path, chunk_store, filters, object_codec, dimension_separator, storage_transformers)\u001b[39m\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m compressor:\n\u001b[32m    453\u001b[39m     \u001b[38;5;66;03m# compatibility with legacy tests using compressor=[]\u001b[39;00m\n\u001b[32m    454\u001b[39m     compressor = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[43m_init_array_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompressor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompressor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunk_store\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobject_codec\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobject_codec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdimension_separator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdimension_separator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_transformers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_transformers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/zarr/storage.py:536\u001b[39m, in \u001b[36m_init_array_metadata\u001b[39m\u001b[34m(store, shape, chunks, dtype, compressor, fill_value, order, overwrite, path, chunk_store, filters, object_codec, dimension_separator, storage_transformers)\u001b[39m\n\u001b[32m    534\u001b[39m \u001b[38;5;66;03m# normalize metadata\u001b[39;00m\n\u001b[32m    535\u001b[39m dtype, object_codec = normalize_dtype(dtype, object_codec)\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m shape = \u001b[43mnormalize_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m + dtype.shape\n\u001b[32m    537\u001b[39m dtype = dtype.base\n\u001b[32m    538\u001b[39m chunks = normalize_chunks(chunks, shape, dtype.itemsize)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/jlab/lib/python3.12/site-packages/zarr/util.py:84\u001b[39m, in \u001b[36mnormalize_shape\u001b[39m\u001b[34m(shape)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Convenience function to normalize the `shape` argument.\"\"\"\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mshape is None\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     86\u001b[39m \u001b[38;5;66;03m# handle 1D convenience form\u001b[39;00m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(shape, numbers.Integral):\n",
      "\u001b[31mTypeError\u001b[39m: shape is None"
     ]
    }
   ],
   "source": [
    "# Inspection of temp data\n",
    "source = da.from_zarr(\"/Users/tobiasschleiss/Documents/DTU/Thesis/output/temp_rechunk.zarr\", component='data')\n",
    "    \n",
    "print(f\"  Source chunks: {source.chunksize}\")\n",
    "print(f\"  Source shape: {source.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2ca5e1-969c-45ad-bee8-8618215f3539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
