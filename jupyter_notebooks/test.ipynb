{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3a4afe6-a286-4e0b-ae00-301823bf8af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported succesfully!\n",
      "2.18.7\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import zarr\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import dask\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "from numcodecs import Blosc\n",
    "from pathlib import Path\n",
    "from ome_zarr.io import parse_url\n",
    "from ome_zarr.writer import write_multiscale\n",
    "\n",
    "print(\"All libraries imported succesfully!\")\n",
    "print(zarr.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "545e33c3-0dad-447e-a7ed-f9e7ffeb1e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion arguments\n",
    "\n",
    "input_path = \"/Users/tobiasschleiss/documents/dtu/thesis/input/brain_2bin_cropSmall.h5\"\n",
    "output_path = \"/Users/tobiasschleiss/Documents/DTU/Thesis/output/test.ome.zarr\"\n",
    "target_chunks = (128, 128, 128)\n",
    "dataset_path = 'exchange/data'\n",
    "max_mem_gb=0.2\n",
    "safety_factor=0.6\n",
    "pyramid_levels = 5\n",
    "downsample_factor=2\n",
    "compression_level=3\n",
    "target_top_level_mb=10\n",
    "\n",
    "n_workers = 2\n",
    "worker_mem = 4 # memory per wroker in GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89ce2e18-4370-4d3b-8581-279bde06dce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Shape: (150, 3768, 2008)\n",
      "  Dtype: float32\n",
      "  Size: 4.23 GB\n",
      "  HDF5 chunks: Contiguous\n"
     ]
    }
   ],
   "source": [
    "# Inspect HDF5 file\n",
    "with h5py.File(input_path, 'r') as f:\n",
    "    if dataset_path not in f:\n",
    "        print(f\"  ERROR: Dataset '{dataset_path}' not found\")\n",
    "        print(f\"  Available paths: {list(f.keys())}\")\n",
    "        \n",
    "    dataset = f[dataset_path]\n",
    "    shape = dataset.shape\n",
    "    dtype = dataset.dtype\n",
    "    h5_chunks = dataset.chunks\n",
    "    data_size_gb = dataset.nbytes / (1024**3)\n",
    "    data_size_mb = dataset.nbytes / (1024**2)\n",
    "    dtype_size = dtype.itemsize\n",
    "        \n",
    "    print(f\"  Shape: {shape}\")\n",
    "    print(f\"  Dtype: {dtype}\")\n",
    "    print(f\"  Size: {data_size_gb:.2f} GB\")\n",
    "    print(f\"  HDF5 chunks: {h5_chunks if h5_chunks else 'Contiguous'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34fa54ec-77a7-4e32-8aad-f83996452667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Block Size Calculation (Memory-Constrained)\n",
      "============================================================\n",
      "Memory budget: 0.20 GB (safety: 60%)\n",
      "Dataset shape: (150, 3768, 2008)\n",
      "Target chunks: (128, 128, 128)\n",
      "\n",
      "⚠️  Full Z-slab (3.87 GB) doesn't fit\n",
      "max y rows: 116\n",
      "  Even one Y-row doesn't fit - using Y-X blocks\n",
      "\n",
      "✓ Strategy: Y-X blocks\n",
      "  Block shape: (128, 1024, 128)\n",
      "  Block size: 0.07 GB\n",
      "  Blocks per dimension: Z:2, Y:4, X:16\n",
      "  Total blocks: 128\n",
      "\n",
      "✓ Strategy: Y-X blocks\n",
      "  Block shape: (128, 512, 384)\n",
      "  Block size: 0.10 GB\n",
      "  Blocks per dimension: Z:2, Y:8, X:6\n",
      "  Total blocks: 96\n",
      "\n",
      "✓ Strategy: Y-X blocks\n",
      "  Block shape: (128, 256, 896)\n",
      "  Block size: 0.12 GB\n",
      "  Blocks per dimension: Z:2, Y:15, X:3\n",
      "  Total blocks: 90\n",
      "\n",
      "✓ Strategy: Y-X blocks\n",
      "  Block shape: (128, 128, 1792)\n",
      "  Block size: 0.12 GB\n",
      "  Blocks per dimension: Z:2, Y:30, X:2\n",
      "  Total blocks: 120\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Cannot fit even minimal block size in 0.20 GB",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 82\u001b[39m\n\u001b[32m     78\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Total blocks: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_blocks\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     80\u001b[39m             \u001b[38;5;66;03m# return block_shape, 'yx_blocks'\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mMemoryError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot fit even minimal block size in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_mem_gb\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m GB\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# Y-blocks with full X\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# Align Y to target chunks\u001b[39;00m\n\u001b[32m     86\u001b[39m block_y = (max_y // target_y) * target_y\n",
      "\u001b[31mMemoryError\u001b[39m: Cannot fit even minimal block size in 0.20 GB"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculate optimal block size when full Z-slabs don't fit.\n",
    "Returns block dimensions that align with target chunks.\n",
    "\"\"\"\n",
    "    \n",
    "z_total, y_total, x_total = shape\n",
    "target_z, target_y, target_x = target_chunks\n",
    "    \n",
    "available_bytes = max_mem_gb * 1e9 * safety_factor\n",
    "    \n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Block Size Calculation (Memory-Constrained)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Memory budget: {max_mem_gb:.2f} GB (safety: {int(safety_factor*100)}%)\")\n",
    "print(f\"Dataset shape: {shape}\")\n",
    "print(f\"Target chunks: {target_chunks}\")\n",
    "    \n",
    "# Try to use target Z (best for zarr alignment)\n",
    "block_z = target_z\n",
    "bytes_for_full_plane = block_z * y_total * x_total * dtype_size\n",
    "    \n",
    "if bytes_for_full_plane <= available_bytes:\n",
    "    # Full Z-slab fits!\n",
    "    block_shape = (block_z, y_total, x_total)\n",
    "    block_gb = bytes_for_full_plane / 1e9\n",
    "    num_blocks = (z_total + block_z - 1) // block_z\n",
    "        \n",
    "    print(f\"\\n✓ Strategy: Full Z-slabs\")\n",
    "    print(f\"  Block shape: {block_shape}\")\n",
    "    print(f\"  Block size: {block_gb:.2f} GB\")\n",
    "    print(f\"  Number of blocks: {num_blocks}\")\n",
    "        \n",
    "    #return block_shape, 'full_slab'\n",
    "    \n",
    "# Full slab doesn't fit - use Y-blocks\n",
    "print(f\"\\n⚠️  Full Z-slab ({bytes_for_full_plane/1e9:.2f} GB) doesn't fit\")\n",
    "    \n",
    "# Calculate max Y that fits with target Z and full X\n",
    "bytes_per_y_row = block_z * x_total * dtype_size\n",
    "max_y = int(available_bytes / bytes_per_y_row)\n",
    "print(f\"max y rows: {max_y}\")\n",
    "    \n",
    "if max_y < target_y:\n",
    "    # Even one Y-row doesn't fit - need X-blocks too\n",
    "    print(f\"  target Y-row doesn't fit - using Y-X blocks\")\n",
    "        \n",
    "    # Calculate Y and X that fit\n",
    "    available_elements = available_bytes / (block_z * dtype_size)\n",
    "        \n",
    "    # Try to keep Y as large as possible, reduce X\n",
    "    for y_mult in [8, 4, 2, 1]:\n",
    "        block_y = target_y * y_mult\n",
    "        if block_y > y_total:\n",
    "            continue\n",
    "            \n",
    "        max_x = int(available_elements / block_y)\n",
    "            \n",
    "        # Align X to target chunks\n",
    "        block_x = (max_x // target_x) * target_x\n",
    "        block_x = max(target_x, block_x)\n",
    "        block_x = min(block_x, x_total)\n",
    "            \n",
    "        block_bytes = block_z * block_y * block_x * dtype_size\n",
    "            \n",
    "        if block_bytes <= available_bytes:\n",
    "            block_shape = (block_z, block_y, block_x)\n",
    "            block_gb = block_bytes / 1e9\n",
    "                \n",
    "            num_z_blocks = (z_total + block_z - 1) // block_z\n",
    "            num_y_blocks = (y_total + block_y - 1) // block_y\n",
    "            num_x_blocks = (x_total + block_x - 1) // block_x\n",
    "            total_blocks = num_z_blocks * num_y_blocks * num_x_blocks\n",
    "                \n",
    "            print(f\"\\n✓ Strategy: Y-X blocks\")\n",
    "            print(f\"  Block shape: {block_shape}\")\n",
    "            print(f\"  Block size: {block_gb:.2f} GB\")\n",
    "            print(f\"  Blocks per dimension: Z:{num_z_blocks}, Y:{num_y_blocks}, X:{num_x_blocks}\")\n",
    "            print(f\"  Total blocks: {total_blocks}\")\n",
    "                \n",
    "            # return block_shape, 'yx_blocks'\n",
    "        \n",
    "    raise MemoryError(f\"Cannot fit even minimal block size in {max_mem_gb:.2f} GB\")\n",
    "    \n",
    "# Y-blocks with full X\n",
    "# Align Y to target chunks\n",
    "block_y = (max_y // target_y) * target_y\n",
    "block_y = max(target_y, block_y)\n",
    "block_y = min(block_y, y_total)\n",
    "    \n",
    "block_shape = (block_z, block_y, x_total)\n",
    "block_gb = block_z * block_y * x_total * dtype_size / 1e9\n",
    "    \n",
    "num_z_blocks = (z_total + block_z - 1) // block_z\n",
    "num_y_blocks = (y_total + block_y - 1) // block_y\n",
    "total_blocks = num_z_blocks * num_y_blocks\n",
    "    \n",
    "print(f\"\\n✓ Strategy: Y-blocks (your approach!)\")\n",
    "print(f\"  Block shape: {block_shape}\")\n",
    "print(f\"  Block size: {block_gb:.2f} GB\")\n",
    "print(f\"  Blocks per Z-slab: {num_y_blocks}\")\n",
    "print(f\"  Total blocks: {total_blocks}\")\n",
    "print(f\"  Note: {num_y_blocks} seeks per Z-slab vs 1 for full slab\")\n",
    "    \n",
    "# return block_shape, 'y_blocks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9f653e1-ba90-4b6c-a9f0-0e5eee77d2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "HDF5 to Zarr with Adaptive Blocking\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (2867855773.py, line 90)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 90\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mreturn root, strategy\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "HDF5 to Zarr conversion with automatic block sizing.\n",
    "Falls back to Y-blocks or Y-X-blocks when memory constrained.\n",
    "\"\"\"\n",
    "    \n",
    "print(\"=\"*60)\n",
    "print(\"HDF5 to Zarr with Adaptive Blocking\")\n",
    "print(\"=\"*60)\n",
    "    \n",
    "with h5py.File(input_path, 'r') as f:\n",
    "    dataset = f[dataset_path]\n",
    "    shape = dataset.shape\n",
    "    dtype = dataset.dtype\n",
    "        \n",
    "    print(f\"\\nDataset: {shape}, {dtype}\")\n",
    "        \n",
    "    # Calculate optimal block size\n",
    "    block_shape, strategy = calculate_optimal_block_size(-----\n",
    "        shape, dtype, target_chunks, max_mem_gb, safety_factor\n",
    "    )\n",
    "        \n",
    "    block_z, block_y, block_x = block_shape\n",
    "    z_total, y_total, x_total = shape\n",
    "        \n",
    "    # Create zarr\n",
    "    root = zarr.open_group(str(output_path), mode='w', zarr_format=2)\n",
    "    compressor = Blosc(cname='zstd', clevel=compression_level, shuffle=Blosc.BITSHUFFLE)\n",
    "        \n",
    "    zarr_array = root.create_dataset(\n",
    "        '0',\n",
    "        shape=shape,\n",
    "        chunks=target_chunks,\n",
    "        dtype=dtype,\n",
    "        compressor=compressor,\n",
    "        dimension_separator='/'\n",
    "    )\n",
    "        \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Writing Data\")\n",
    "    print(f\"{'='*60}\")\n",
    "        \n",
    "    start_time = time.time()\n",
    "    block_count = 0\n",
    "        \n",
    "    # Calculate total blocks\n",
    "    total_blocks = (\n",
    "        ((z_total + block_z - 1) // block_z) *\n",
    "        ((y_total + block_y - 1) // block_y) *\n",
    "        ((x_total + block_x - 1) // block_x)\n",
    "    )\n",
    "        \n",
    "    print(f\"Processing {total_blocks} blocks...\")\n",
    "        \n",
    "    # Iterate over blocks\n",
    "    for z_start in range(0, z_total, block_z):\n",
    "        z_end = min(z_start + block_z, z_total)\n",
    "            \n",
    "        for y_start in range(0, y_total, block_y):\n",
    "            y_end = min(y_start + block_y, y_total)\n",
    "                \n",
    "            for x_start in range(0, x_total, block_x):\n",
    "                x_end = min(x_start + block_x, x_total)\n",
    "                    \n",
    "                block_count += 1\n",
    "                    \n",
    "                # Read block from HDF5\n",
    "                block = dataset[z_start:z_end, y_start:y_end, x_start:x_end]\n",
    "                    \n",
    "                # Write to zarr (zarr will internally chunk to target_chunks)\n",
    "                zarr_array[z_start:z_end, y_start:y_end, x_start:x_end] = block\n",
    "                    \n",
    "                del block\n",
    "                    \n",
    "                # Progress reporting\n",
    "                if block_count % 10 == 0 or block_count == total_blocks:\n",
    "                    elapsed = time.time() - start_time\n",
    "                    rate = block_count / elapsed if elapsed > 0 else 0\n",
    "                    eta = (total_blocks - block_count) / rate if rate > 0 else 0\n",
    "                    progress = block_count / total_blocks * 100\n",
    "                    \n",
    "                    print(f\"  Block {block_count:4d}/{total_blocks} ({progress:5.1f}%) - \"\n",
    "                          f\"{rate:5.1f} blocks/s - ETA: {eta:6.0f}s\")\n",
    "        \n",
    "    elapsed = time.time() - start_time\n",
    "    throughput = (np.prod(shape) * np.dtype(dtype).itemsize / 1e9) / elapsed\n",
    "        \n",
    "    print(f\"\\n✓ Level 0 complete in {elapsed:.1f}s\")\n",
    "    print(f\"  Throughput: {throughput:.2f} GB/s\")\n",
    "        \n",
    "    return root, strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62266f64-ccc6-424e-83fc-d396b9168378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
